{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Job Matching using Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "CV Job Matching using Doc2Vec is a technique that aims to match job descriptions with resumes by representing them as numerical vectors using the Doc2Vec model. This approach allows for efficient comparison and similarity calculation between textual documents.\n",
    "\n",
    "In the field of machine learning, representing text documents numerically is a challenging task. However, it is essential for various applications, such as document retrieval, web search, spam filtering, and topic modeling. Doc2Vec, a variation of the Word2Vec algorithm, provides a solution by generating vector representations from words.\n",
    "\n",
    "**Word2Vec** algorithms, such as **Continuous Bag-of-Words (CBOW)** and **Skip-Gram**, are used to create Word2Vec representations. CBOW predicts the current word based on the surrounding words in a sliding window context. Each word is then converted into a feature vector, and these vectors become the word vectors after training. On the other hand, Skip-Gram predicts the surrounding words given the current word. It is slower than CBOW but is known for its accuracy with infrequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "To implement CV Job Matching using Doc2Vec, we start by importing the necessary libraries and loading the job data from a CSV file. We preprocess the data, keeping only the relevant columns, and merge them into a new column called 'data.' Then, we tokenize the words in the 'data' column and tag them with unique identifiers using the TaggedDocument class.\n",
    "\n",
    "Next, we initialize the Doc2Vec model with specific parameters, such as the vector size, minimum count, and number of epochs. We build the vocabulary by feeding the tagged data to the model, and then train the model on the tagged data.\n",
    "\n",
    "After training, we save the model for future use. To match a resume with a job description, we load the saved model and preprocess the resume and job description text. We convert them to lowercase, remove punctuation and numerical values.\n",
    "\n",
    "Using the trained model, we infer the document vectors for the resume and job description. Then, we calculate the cosine similarity between the two vectors to determine the match between the resume and the job description. The cosine similarity score ranges from -1 to 1, with 1 indicating a perfect match and -1 indicating no similarity.\n",
    "\n",
    "By employing Doc2Vec and cosine similarity, this approach enables efficient and effective matching between job descriptions and resumes, helping to streamline the job application process and enhance the chances of finding the right candidates for specific positions.\n",
    "\n",
    "Finally, the author also employs Gauge chart from Plotly to show the matching percentage with threshold that users could consider modifying thier CV to pass Application Tracking System (TSA) from the majority of employers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding\n",
    "#### 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDFUjQi3S171"
   },
   "outputs": [],
   "source": [
    "## Install all dependencies\n",
    "# !pip install gensim\n",
    "# !pip install nltk\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install requests\n",
    "#!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kpZnVCxZSQ8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy.linalg import norm\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prepare data\n",
    "This dataset that we trained our model contains current job postings available on the City of New York’s official jobs site in 2020. You can follow this link to download: \n",
    "[New York Job Posting Dataset](https://data.world/city-of-ny/kpav-sd4t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "5CoVK6-iSWsU",
    "outputId": "20a60cf2-8224-47a2-d43c-b20d351db269"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intitule_poste</th>\n",
       "      <th>entreprise</th>\n",
       "      <th>secteur_entreprise</th>\n",
       "      <th>description</th>\n",
       "      <th>salaire</th>\n",
       "      <th>experience</th>\n",
       "      <th>education</th>\n",
       "      <th>competences</th>\n",
       "      <th>ville</th>\n",
       "      <th>adresse_complete</th>\n",
       "      <th>...</th>\n",
       "      <th>salaire_max</th>\n",
       "      <th>salaire_moyen</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>duree_min</th>\n",
       "      <th>duree_max</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>recherche_effectuee</th>\n",
       "      <th>site_source</th>\n",
       "      <th>description_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ingénieur QA (Equipe Solution) (H/F)</td>\n",
       "      <td>Datanumia</td>\n",
       "      <td>Logiciels, Energie, SocialTech / GreenTech</td>\n",
       "      <td>En adoptant la démarche DORA, Datanumia favori...</td>\n",
       "      <td>Non spécifié</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non spécifié</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Courbevoie</td>\n",
       "      <td>4 Place des Vosges, 92400 Courbevoie, France</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.892859</td>\n",
       "      <td>2.248062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data</td>\n",
       "      <td>Welcome to the Jungle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consultant senior Data (H/F)</td>\n",
       "      <td>Klint</td>\n",
       "      <td>Logiciels, Digital Marketing / Data Marketing,...</td>\n",
       "      <td>Rejoignez notre équipe de spécialistes Data en...</td>\n",
       "      <td>55K à 70K €</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bac +5</td>\n",
       "      <td>collaboration et travail déquipe, power bi</td>\n",
       "      <td>Levallois-Perret</td>\n",
       "      <td>74 Rue Anatole France, 92300 Levallois-Perret,...</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>48.892646</td>\n",
       "      <td>2.284642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data</td>\n",
       "      <td>Welcome to the Jungle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consultant Data Engineer / Big Data (H/F)</td>\n",
       "      <td>MP DATA</td>\n",
       "      <td>Intelligence artificielle / Machine Learning, ...</td>\n",
       "      <td>Dans un contexte de croissance continue de nos...</td>\n",
       "      <td>40K à 58K €</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non spécifié</td>\n",
       "      <td>communication, langages de programmation</td>\n",
       "      <td>Balma</td>\n",
       "      <td>3 Rue de Vidailhan, 31130 Balma, France</td>\n",
       "      <td>...</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>43.626219</td>\n",
       "      <td>1.488673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data</td>\n",
       "      <td>Welcome to the Jungle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Engineer  (H/F) | Stage</td>\n",
       "      <td>Datascientest</td>\n",
       "      <td>SaaS / Cloud Services, EdTech, Formation</td>\n",
       "      <td>Le MLOps est aujourd’hui incontournable pour i...</td>\n",
       "      <td>Non spécifié</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non spécifié</td>\n",
       "      <td>machine learning, tensorflow, kubernetes, pytorch</td>\n",
       "      <td>Puteaux</td>\n",
       "      <td>1 Terrasse Bellini, 92800 Puteaux, France</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.886942</td>\n",
       "      <td>2.251445</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>data</td>\n",
       "      <td>Welcome to the Jungle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analytics Engineer - Confirmé·e</td>\n",
       "      <td>JAKALA</td>\n",
       "      <td>Digital Marketing / Data Marketing, Big Data, ...</td>\n",
       "      <td>Au sein de notre Practice Data &amp; AI , tu trava...</td>\n",
       "      <td>Non spécifié</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bac +5</td>\n",
       "      <td>rédaction technique, travail déquipe, visualis...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Découvrir</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.844696</td>\n",
       "      <td>2.436650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data</td>\n",
       "      <td>Welcome to the Jungle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              intitule_poste     entreprise  \\\n",
       "0       Ingénieur QA (Equipe Solution) (H/F)      Datanumia   \n",
       "1               Consultant senior Data (H/F)          Klint   \n",
       "2  Consultant Data Engineer / Big Data (H/F)        MP DATA   \n",
       "3   Machine Learning Engineer  (H/F) | Stage  Datascientest   \n",
       "4            Analytics Engineer - Confirmé·e         JAKALA   \n",
       "\n",
       "                                  secteur_entreprise  \\\n",
       "0         Logiciels, Energie, SocialTech / GreenTech   \n",
       "1  Logiciels, Digital Marketing / Data Marketing,...   \n",
       "2  Intelligence artificielle / Machine Learning, ...   \n",
       "3           SaaS / Cloud Services, EdTech, Formation   \n",
       "4  Digital Marketing / Data Marketing, Big Data, ...   \n",
       "\n",
       "                                         description       salaire  \\\n",
       "0  En adoptant la démarche DORA, Datanumia favori...  Non spécifié   \n",
       "1  Rejoignez notre équipe de spécialistes Data en...   55K à 70K €   \n",
       "2  Dans un contexte de croissance continue de nos...   40K à 58K €   \n",
       "3  Le MLOps est aujourd’hui incontournable pour i...  Non spécifié   \n",
       "4  Au sein de notre Practice Data & AI , tu trava...  Non spécifié   \n",
       "\n",
       "   experience     education  \\\n",
       "0         NaN  Non spécifié   \n",
       "1         5.0        Bac +5   \n",
       "2         NaN  Non spécifié   \n",
       "3         NaN  Non spécifié   \n",
       "4         3.0        Bac +5   \n",
       "\n",
       "                                         competences             ville  \\\n",
       "0                                                NaN        Courbevoie   \n",
       "1         collaboration et travail déquipe, power bi  Levallois-Perret   \n",
       "2           communication, langages de programmation             Balma   \n",
       "3  machine learning, tensorflow, kubernetes, pytorch           Puteaux   \n",
       "4  rédaction technique, travail déquipe, visualis...             Paris   \n",
       "\n",
       "                                    adresse_complete  ... salaire_max  \\\n",
       "0       4 Place des Vosges, 92400 Courbevoie, France  ...         NaN   \n",
       "1  74 Rue Anatole France, 92300 Levallois-Perret,...  ...     70000.0   \n",
       "2            3 Rue de Vidailhan, 31130 Balma, France  ...     58000.0   \n",
       "3          1 Terrasse Bellini, 92800 Puteaux, France  ...         NaN   \n",
       "4                                          Découvrir  ...         NaN   \n",
       "\n",
       "  salaire_moyen   latitude longitude duree_min duree_max duree_moyenne  \\\n",
       "0           NaN  48.892859  2.248062       NaN       NaN           NaN   \n",
       "1       62500.0  48.892646  2.284642       NaN       NaN           NaN   \n",
       "2       49000.0  43.626219  1.488673       NaN       NaN           NaN   \n",
       "3           NaN  48.886942  2.251445       3.0       6.0           4.5   \n",
       "4           NaN  48.844696  2.436650       NaN       NaN           NaN   \n",
       "\n",
       "  recherche_effectuee            site_source  description_company  \n",
       "0                data  Welcome to the Jungle                  NaN  \n",
       "1                data  Welcome to the Jungle                  NaN  \n",
       "2                data  Welcome to the Jungle                  NaN  \n",
       "3                data  Welcome to the Jungle                  NaN  \n",
       "4                data  Welcome to the Jungle                  NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('jobs.csv')\n",
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since head() fuction does not show all data, we check column names to retain only necessary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intitule_poste</th>\n",
       "      <th>description</th>\n",
       "      <th>education</th>\n",
       "      <th>competences</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ingénieur QA (Equipe Solution) (H/F)</td>\n",
       "      <td>En adoptant la démarche DORA, Datanumia favori...</td>\n",
       "      <td>Formation requise : Non spécifié</td>\n",
       "      <td>Compétences requises : nan</td>\n",
       "      <td>Experiences requises : nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consultant senior Data (H/F)</td>\n",
       "      <td>Rejoignez notre équipe de spécialistes Data en...</td>\n",
       "      <td>Formation requise : Bac +5</td>\n",
       "      <td>Compétences requises : collaboration et travai...</td>\n",
       "      <td>Experiences requises : 5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consultant Data Engineer / Big Data (H/F)</td>\n",
       "      <td>Dans un contexte de croissance continue de nos...</td>\n",
       "      <td>Formation requise : Non spécifié</td>\n",
       "      <td>Compétences requises : communication, langages...</td>\n",
       "      <td>Experiences requises : nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Engineer  (H/F) | Stage</td>\n",
       "      <td>Le MLOps est aujourd’hui incontournable pour i...</td>\n",
       "      <td>Formation requise : Non spécifié</td>\n",
       "      <td>Compétences requises : machine learning, tenso...</td>\n",
       "      <td>Experiences requises : nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analytics Engineer - Confirmé·e</td>\n",
       "      <td>Au sein de notre Practice Data &amp; AI , tu trava...</td>\n",
       "      <td>Formation requise : Bac +5</td>\n",
       "      <td>Compétences requises : rédaction technique, tr...</td>\n",
       "      <td>Experiences requises : 3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              intitule_poste  \\\n",
       "0       Ingénieur QA (Equipe Solution) (H/F)   \n",
       "1               Consultant senior Data (H/F)   \n",
       "2  Consultant Data Engineer / Big Data (H/F)   \n",
       "3   Machine Learning Engineer  (H/F) | Stage   \n",
       "4            Analytics Engineer - Confirmé·e   \n",
       "\n",
       "                                         description  \\\n",
       "0  En adoptant la démarche DORA, Datanumia favori...   \n",
       "1  Rejoignez notre équipe de spécialistes Data en...   \n",
       "2  Dans un contexte de croissance continue de nos...   \n",
       "3  Le MLOps est aujourd’hui incontournable pour i...   \n",
       "4  Au sein de notre Practice Data & AI , tu trava...   \n",
       "\n",
       "                          education  \\\n",
       "0  Formation requise : Non spécifié   \n",
       "1        Formation requise : Bac +5   \n",
       "2  Formation requise : Non spécifié   \n",
       "3  Formation requise : Non spécifié   \n",
       "4        Formation requise : Bac +5   \n",
       "\n",
       "                                         competences  \\\n",
       "0                         Compétences requises : nan   \n",
       "1  Compétences requises : collaboration et travai...   \n",
       "2  Compétences requises : communication, langages...   \n",
       "3  Compétences requises : machine learning, tenso...   \n",
       "4  Compétences requises : rédaction technique, tr...   \n",
       "\n",
       "                   experience  \n",
       "0  Experiences requises : nan  \n",
       "1  Experiences requises : 5.0  \n",
       "2  Experiences requises : nan  \n",
       "3  Experiences requises : nan  \n",
       "4  Experiences requises : 3.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show column name\n",
    "df['experience'] = \"Experiences requises : \" + df['experience'].astype(str)\n",
    "df['competences'] = \"Compétences requises : \" + df['competences'].astype(str)\n",
    "df['education'] = \"Formation requise : \" + df['education'].astype(str)\n",
    "\n",
    "df = df[['intitule_poste','description','education','competences','experience']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only some columns to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  \\\n",
      "0  En adoptant la démarche DORA, Datanumia favori...   \n",
      "1  Rejoignez notre équipe de spécialistes Data en...   \n",
      "2  Dans un contexte de croissance continue de nos...   \n",
      "3  Le MLOps est aujourd’hui incontournable pour i...   \n",
      "4  Au sein de notre Practice Data & AI , tu trava...   \n",
      "\n",
      "                                                data  \n",
      "0  Ingénieur QA (Equipe Solution) (H/F) Formation...  \n",
      "1  Consultant senior Data (H/F) Formation requise...  \n",
      "2  Consultant Data Engineer / Big Data (H/F) Form...  \n",
      "3  Machine Learning Engineer  (H/F) | Stage Forma...  \n",
      "4  Analytics Engineer - Confirmé·e Formation requ...  \n"
     ]
    }
   ],
   "source": [
    "# Create a new column called 'data' and merge the values of the other columns into it\n",
    "df['data'] = df[['intitule_poste','education','competences','experience']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "# Drop the individual columns if you no longer need them\n",
    "df.drop(['intitule_poste','education','competences','experience'], axis=1, inplace=True)\n",
    "# Preview the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenize data\n",
    "We tokenize the words in the 'data' column and tag them with unique identifiers using the TaggedDocument class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sCAMBUD8Sorw"
   },
   "outputs": [],
   "source": [
    "# Tag data\n",
    "data = list(df['data'])\n",
    "tagged_data = [TaggedDocument(words = word_tokenize(_d.lower()), tags = [str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model initialization and vocabulary buiding\n",
    "Next, we initialize the Doc2Vec model with specific parameters.\n",
    "\n",
    "**Parameters** of Doc2Vec are as follows: \n",
    "\n",
    "- `vector_size`: Dimensionality of the feature vectors. Default: 100.\n",
    "- `window`: The window refers to the maximum distance between the target word and its context words within a sentence. Default: 5.\n",
    "- `min_count`: Ignores all words with a total frequency lower than this. Default: 5.\n",
    "- `epochs`: Number of iterations (epochs) over the corpus. Defaults to 5 for PV-DBOW and 10 for PV-DM.\n",
    "- `dm`: Defines the training algorithm. If `dm = 1`, the Distributed Memory (PV-DM) model is used. If `dm = 0`, the Distributed Bag of Words (PV-DBOW) model is used. Default: 1 (PV-DM).\n",
    "- `dbow_words`: If set to 1, trains word vectors (in addition to document vectors) using the PV-DBOW algorithm. Default: 0 (False).\n",
    "- `dm_mean`: If set to 1, uses the mean of the context word vectors instead of concatenation when inferring vectors in the PV-DM model. Default: 0 (False).\n",
    "- `dm_concat`: If set to 1, concatenates the document and context word vectors when inferring vectors in the PV-DM model. Default: 0 (False).\n",
    "- `dm_tag_count`: Expected number of document tags per document, when using the PV-DM algorithm. Default: 1.\n",
    "- `dbow_tag_count`: Expected number of document tags per document, when using the PV-DBOW algorithm. Default: 1.\n",
    "- `alpha`: The initial learning rate. Default: 0.025.\n",
    "- `min_alpha`: The learning rate will linearly drop to `min_alpha` as training progresses. Default: 0.0001.\n",
    "- `hs`: If set to 1, hierarchical softmax activation function will be used. Default: 0 (Negative Sampling).\n",
    "- `negative`: If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drawn. Default: 5.\n",
    "- `ns_exponent`: The exponent used to shape the negative sampling distribution. Default: 0.75.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pN_H6onBTamK"
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = Doc2Vec(vector_size = 50,\n",
    "min_count = 5,\n",
    "epochs = 100,\n",
    "alpha = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Sv_Mtx4OWFgF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary building\n",
    "model.build_vocab(tagged_data)\n",
    "# Get the vocabulary keys\n",
    "keys = model.wv.key_to_index.keys()\n",
    "# Print the length of the vocabulary keys\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Train and save the model\n",
    "Train the model on tagged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0jwx4eNAWYrI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/100\n",
      "Training epoch 2/100\n",
      "Training epoch 3/100\n",
      "Training epoch 4/100\n",
      "Training epoch 5/100\n",
      "Training epoch 6/100\n",
      "Training epoch 7/100\n",
      "Training epoch 8/100\n",
      "Training epoch 9/100\n",
      "Training epoch 10/100\n",
      "Training epoch 11/100\n",
      "Training epoch 12/100\n",
      "Training epoch 13/100\n",
      "Training epoch 14/100\n",
      "Training epoch 15/100\n",
      "Training epoch 16/100\n",
      "Training epoch 17/100\n",
      "Training epoch 18/100\n",
      "Training epoch 19/100\n",
      "Training epoch 20/100\n",
      "Training epoch 21/100\n",
      "Training epoch 22/100\n",
      "Training epoch 23/100\n",
      "Training epoch 24/100\n",
      "Training epoch 25/100\n",
      "Training epoch 26/100\n",
      "Training epoch 27/100\n",
      "Training epoch 28/100\n",
      "Training epoch 29/100\n",
      "Training epoch 30/100\n",
      "Training epoch 31/100\n",
      "Training epoch 32/100\n",
      "Training epoch 33/100\n",
      "Training epoch 34/100\n",
      "Training epoch 35/100\n",
      "Training epoch 36/100\n",
      "Training epoch 37/100\n",
      "Training epoch 38/100\n",
      "Training epoch 39/100\n",
      "Training epoch 40/100\n",
      "Training epoch 41/100\n",
      "Training epoch 42/100\n",
      "Training epoch 43/100\n",
      "Training epoch 44/100\n",
      "Training epoch 45/100\n",
      "Training epoch 46/100\n",
      "Training epoch 47/100\n",
      "Training epoch 48/100\n",
      "Training epoch 49/100\n",
      "Training epoch 50/100\n",
      "Training epoch 51/100\n",
      "Training epoch 52/100\n",
      "Training epoch 53/100\n",
      "Training epoch 54/100\n",
      "Training epoch 55/100\n",
      "Training epoch 56/100\n",
      "Training epoch 57/100\n",
      "Training epoch 58/100\n",
      "Training epoch 59/100\n",
      "Training epoch 60/100\n",
      "Training epoch 61/100\n",
      "Training epoch 62/100\n",
      "Training epoch 63/100\n",
      "Training epoch 64/100\n",
      "Training epoch 65/100\n",
      "Training epoch 66/100\n",
      "Training epoch 67/100\n",
      "Training epoch 68/100\n",
      "Training epoch 69/100\n",
      "Training epoch 70/100\n",
      "Training epoch 71/100\n",
      "Training epoch 72/100\n",
      "Training epoch 73/100\n",
      "Training epoch 74/100\n",
      "Training epoch 75/100\n",
      "Training epoch 76/100\n",
      "Training epoch 77/100\n",
      "Training epoch 78/100\n",
      "Training epoch 79/100\n",
      "Training epoch 80/100\n",
      "Training epoch 81/100\n",
      "Training epoch 82/100\n",
      "Training epoch 83/100\n",
      "Training epoch 84/100\n",
      "Training epoch 85/100\n",
      "Training epoch 86/100\n",
      "Training epoch 87/100\n",
      "Training epoch 88/100\n",
      "Training epoch 89/100\n",
      "Training epoch 90/100\n",
      "Training epoch 91/100\n",
      "Training epoch 92/100\n",
      "Training epoch 93/100\n",
      "Training epoch 94/100\n",
      "Training epoch 95/100\n",
      "Training epoch 96/100\n",
      "Training epoch 97/100\n",
      "Training epoch 98/100\n",
      "Training epoch 99/100\n",
      "Training epoch 100/100\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(model.epochs):\n",
    "    print(f\"Training epoch {epoch+1}/{model.epochs}\")\n",
    "    model.train(tagged_data, \n",
    "                total_examples=model.corpus_count, \n",
    "                epochs=model.epochs)\n",
    "\n",
    "model.save('cv_job_maching.model')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFXCiT8GWgdP"
   },
   "source": [
    "#### 6. Inputs of CV and JD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Resume**:\n",
    "\n",
    "In this case, I assume that we upload our CV in PDF file, so I use PyPDF2 to extract data. You can also change how to read inputs appropreately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BK-fllx0WglI"
   },
   "outputs": [],
   "source": [
    "pdf = PyPDF2.PdfReader('./cv/CV_Lucas_Coussy_english_version.pdf')\n",
    "resume = \"\"\n",
    "for i in range(len(pdf.pages)):\n",
    "    pageObj = pdf.pages[i]\n",
    "    resume += pageObj.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # pymupdf\n",
    "\n",
    "# doc = fitz.open(\"./cv/CV_Lucas_Coussy_english_version.pdf\")\n",
    "\n",
    "# resume_ = \"\"\n",
    "# for page in doc:\n",
    "#     resume_ += page.get_text(\"text\") + \"\\n\"\n",
    "\n",
    "# print(resume_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Job Description**:\n",
    "\n",
    "From my perspective, I believe candidates will copy and paste the JD into textbox to check the matching percentage, so I will have JD Input in text as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uMuC1hBtWqmr"
   },
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "We are looking for a highly motivated individual to join our AI Special Forces team. \n",
    "A person who is passionate about delivering fast, effective, and high-quality support to clients, and is driven by the potential of technology and AI. \n",
    "This role is perfect for someone who loves solving problems, is highly organized, and has a strong inteZrest in technology and AI.\n",
    "\\nAs an AI Special Forces Specialist, you will play a critical role, acting as the first line of defense when clients encounter issues with their AI agents or \n",
    "need to integrate them with external systems. \n",
    "You\\u2019ll work directly with customers to resolve questions, troubleshoot technical problems, and collaborate with internal teams (CS, Onboarding, Product, and Engineering) \n",
    "to ensure issues are resolved promptly and thoroughly. \n",
    "Your work is key to maintaining strong client relationships and ensuring satisfaction with the Darwin AI experience\\n.\n",
    "\\nIn this role, you will:\\nRespond to customer inquiries via WhatsApp, email, and Slack, ensuring fast responses and high customer satisfaction.\n",
    "\\nTroubleshoot and resolve technical problems, especially those related to AI behavior, configuration, and API integrations\n",
    "\\nMonitor and act on alerts from internal tools like Slack channels and customer feedback submitted in the Darwin platform\n",
    "\\nWork closely with Product and Engineering teams, escalating complex issues and contributing to product improvements.\n",
    "\\nDocument support activity in the appropriate platform, maintaining accurate logs of issues and resolutions.\n",
    "\\nIdentify recurring issues and contribute to internal documentation and FAQs.\\nCollaborate with the Customer Success and Onboarding teams to ensure a seamless customer experience.\n",
    "\\nAudit AI conversations to detect bugs or opportunities for improvement.\n",
    "\\nEnsure that all critical feedback and issues are resolved within the SLA.\n",
    "\\nRequirements\n",
    "\\nExperience in Customer Support, Technical Support, or Helpdesk roles, ideally in SaaS or tech environments.\n",
    "\\nStrong troubleshooting skills and ability to resolve issues efficiently.\n",
    "\\nFamiliarity with AI behavior, JSON structures, and state machines (training provided).\n",
    "\\nExperience with AI configuration, WhatsApp, APIs, and third-party integrations.\\nKnowledge of process automation; experience with Zapier is a plus.\n",
    "\\nProgramming knowledge, especially in Python, is a plus.\\nAbility to explain technical concepts clearly to both technical and non-technical audiences\n",
    "\\nHighly organized, with the ability to manage multiple support cases at once.\\nStrong written and verbal communication skills.\n",
    "\\nA customer-first mindset with a genuine desire to help clients succeed.\\nA team player with adaptability in fast-paced environments.\n",
    "\\nPassion for technology, AI, and continuous learning.\\nBenefits\\n\\u25cf\\nLanguage Classes:\n",
    "\\nAccess to language classes (English, Portuguese, Spanish) to enhance communication skills.\n",
    "\\n\\u25cf\\nOpenAI or Gemini Premium License:\\nComplimentary access to an OpenAI premium license for personal or professional use.\n",
    "\\n\\u25cf\\nPaid Time Off:\\nEnjoy 25 days\\/year of paid vacations and holidays to recharge and maintain a healthy work-life balance.\n",
    "\\n\\u25cf\\nSoft Hybrid Work:\\nWe meet 3 days\\/month in our Co Work offices, the rest of the time you can work remotely from wherever you like!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jd = \"We are seeking a Computer Vision Engineer with strong software and AI fundamentals to build and deploy high-performance AI models. You will handle the full pipeline\\u2014from training detection and segmentation models to optimizing them for production using NVIDIA TensorRT and Docker.\\nCore Responsibilities\\nModel Training: Train and fine-tune models for Detection, Classification, and Segmentation (e.g., YOLO, ResNet, U-Net).\\nTracking: Implement Multi-Object Tracking (MOT) algorithms for complex video streams.\\nEngineering: Write production-grade Python code with a focus on modularity and scalability.\\nDeployment: Containerize applications using Docker for consistent deployment.\\nRequirements\\n3+ years in CV\\/Deep Learning.\\nPython, PyTorch, OpenCV.\\nStrong preference for experience with NVIDIA TensorRT and model optimization (quantization\\/pruning).\\nSolid grasp of software engineering principles (Git, testing, CI\\/CD).\\nCan work on other non-vision AI implementations\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"We are expanding rapidly and looking to hire four passionate\\nComputer Vision Engineers\\nto join our growing team. Ideal candidates should have at least\\n2 years of professional experience\\nin the industry or as an academic postgraduate researchers, having practical and theoretical knowledge in Machine Learning, Computer\\/Machine Vision and Visual-Language Models (VLMs). Skills on embedded programming will be acknowledged, to explore the most efficient and practical algorithmic implementations in embedded platforms.\\nIn this role, you should be able to work with an agile team of experienced engineers, solving complex vision AI problems by developing cutting edge technology. You will be involved in various products and product development phases working alongside some of the most talented people in the industry.\\nMandatory: Fulfilled army obligations (for male candidates) \\u2013 Please report it in your application CV\\nRequirements\\nCandidates should have a BSc degree in Electrical & Computer Engineering \\/ Computer Science, and in addition:\\nProven work experience as a SW Engineer (>2yrs of working experience), especially:\\nProgramming experience with Python packages such as Scikit-learn PyTorch.\\nExperience in object-oriented programming in C++ and Python.\\nMust have proven knowledge of computer vision and machine learning principles and algorithms (e.g. MSc or PhD in computer vision or machine learning) or relevant proven experience.\\nExperience with image segmentation, image classification and object detection deep learning models as well as CNNs, RNNs\\/LSTMs, VLMs, Zero shot and open-set architectures, Vision Transformers etc.\\nAbility to work with cross functional teams.\\nAbility to learn new programming languages and technologies.\\nDesired (but not mandatory) Skills:\\nFamiliarity with Diffusion Models for image generation and enhancement.\\n3D Computer Vision and Spatial Understanding.\\nDepth Estimation & 3D Reconstruction: Working with point clouds, LiDAR data and stereo imaging.\\nSimultaneous Localization and Mapping (SLAM): Developing algorithms for real-time mapping and navigation in robotics.\\nEmbedded software background and understanding of embedded system architectures.\\nHands on experience with Docker and microservice oriented development.\\nCode versioning (Git) and MLOps.\\nDemonstrated proactiveness and enthusiasm for technology, with a commitment to delivering high-quality results within an evolving environment.\\nBenefits\\nWork in a dynamic and pleasant environment at a fast-paced company\\nDiscuss\\/interact with tech-leaders at global scale, using cutting-edge tech and driving new markets\\nCompetitive remuneration package\\nHuge room for creativity and innovation\\nPrivate medical insurance\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Develop a function to pre-process input text**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nY1-Fn97WgoN"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation from the text\n",
    "    text = re.sub('[^a-z]', ' ', text)\n",
    "    \n",
    "    # Remove numerical values from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'education education master iref erds university of bordeaux bordeaux bachelor s degree in mathematics university of clerm ont auvergne clerm ont ferrand preparatory class mpsi mathematics physics engineering lyc e lafayette clermont ferrand exp riences exp riences observation internship in data science beys clerm ont ferrand national mathematics competition concours g n ral lyc e jeanne d arc clerm ont ferrandjanuary march about me about mestudent in statistics and economics with a strong interest in artificial intelligence and machine learning i design projects combining data analysis and machine learning models which i regularly publish on my github lucas coussy data science internship contact coussy lucas gmail com rue blaise pascale talence linkedin com in lucas coussy b driver s license b native b toeiclanguages french english skills python pandas tensorflow keras seaborn r vba sql excel pow er bi interests ai street w orkout m athem atics m usic https github com lucas coussy projects projects yolov object detection reimplementation of the yolov model in pytorch from the original paper trained on pascal voc cbow word embedding visualization re coding of the cbow model and development of tools for word s vector visualization aircraft engine fault detection built classification models using logistic regression and neural networks with optimized hyperparameters text summarization benchmark compared multiple summarization models bart flan t led phi etc on lord of the mysteries chapters using rouge and bert scores'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J4TR1IklWqp8"
   },
   "outputs": [],
   "source": [
    "# Apply to CV and JD\n",
    "input_CV = preprocess_text(resume)\n",
    "input_JD = preprocess_text(jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Matching\n",
    "Using the trained model, we infer the document vectors for the resume and job description. Then, we calculate the cosine similarity between the two vectors to determine the match between the resume and the job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qlbOvGLfWqsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.69\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "model = Doc2Vec.load('cv_job_maching.model')\n",
    "v1 = model.infer_vector(input_CV.split())\n",
    "v2 = model.infer_vector(input_JD.split())\n",
    "similarity = 100*(np.dot(np.array(v1), np.array(v2))) / (norm(np.array(v1)) * norm(np.array(v2)))\n",
    "print(round(similarity, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Visualization and Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "gauge": {
          "axis": {
           "range": [
            0,
            100
           ]
          },
          "steps": [
           {
            "color": "#FFB6C1",
            "range": [
             0,
             50
            ]
           },
           {
            "color": "#FFFFE0",
            "range": [
             50,
             70
            ]
           },
           {
            "color": "#90EE90",
            "range": [
             70,
             100
            ]
           }
          ],
          "threshold": {
           "line": {
            "color": "red",
            "width": 4
           },
           "thickness": 0.75,
           "value": 100
          }
         },
         "mode": "gauge+number",
         "title": {
          "text": "Matching percentage (%)"
         },
         "type": "indicator",
         "value": 73.68955960467964
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mExcellent! You can submit your CV.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "fig = go.Figure(go.Indicator(\n",
    "    domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "    value = similarity,\n",
    "    mode = \"gauge+number\",\n",
    "    title = {'text': \"Matching percentage (%)\"},\n",
    "    #delta = {'reference': 100},\n",
    "    gauge = {\n",
    "        'axis': {'range': [0, 100]},\n",
    "        'steps' : [\n",
    "            {'range': [0, 50], 'color': \"#FFB6C1\"},\n",
    "            {'range': [50, 70], 'color': \"#FFFFE0\"},\n",
    "            {'range': [70, 100], 'color': \"#90EE90\"}\n",
    "        ],\n",
    "             'threshold' : {'line': {'color': \"red\", 'width': 4}, 'thickness': 0.75, 'value': 100}}))\n",
    "\n",
    "fig.update_layout(width=600, height=400)  # Adjust the width and height as desired\n",
    "fig.show()\n",
    "\n",
    "# Print notification\n",
    "if similarity < 50:\n",
    "    print(colored(\"Low chance, need to modify your CV!\", \"red\", attrs=[\"bold\"]))\n",
    "elif similarity >= 50 and similarity < 70:\n",
    "    print(colored(\"Good chance but you can improve further!\", \"yellow\", attrs=[\"bold\"]))\n",
    "else:\n",
    "    print(colored(\"Excellent! You can submit your CV.\", \"green\", attrs=[\"bold\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgment\n",
    "\n",
    "This implementation is a **modified version of the Doc2Vec notebook** originally provided by the authors.  \n",
    "Their original work served as the foundation for this implementation, which has been adapted and extended to fit the specific needs of this project.\n",
    "\n",
    "Original notebook to find [here](https://github.com/kirudang/CV-Job-matching).  \n",
    "Original model architecture to find [here](https://github.com/jhlau/doc2vec).\\\n",
    "All credit for the original approach and implementation goes to the original authors.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
